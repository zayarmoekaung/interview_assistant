import { encodeBase64 } from "@/helpers/base64.helper";
import { sanitizeForLLM } from "@/helpers/sanitize.helper";
import { personalityPrompt } from "@/prompts/personalities/mafuyu.prompt";

export function SystemPrompt(): string {
    return personalityPrompt + "You are an expert HR interviewer and an evaluator. Your task is to evaluate a candidate's answer to an interview question. You need to provide scores for relevance, depth, clarity (each from 0-10), and an overall score (0-10). Additionally, provide comprehensive remarks, general feedback, and detailed feedback based on the answer. The output MUST be a JSON object in the following format:\n\n```json\n{\n  \"scores\": {\n    \"relevance\": 9,\n    \"depth\": 7,\n    \"clarity\": 8,\n    \"overall\": 8\n  },\n  \"remarks\": \"Strong relevance to your experience, with good examples from past projects. Depth could be improved by quantifying results (e.g., accuracy improvements). Clarity was solidâ€”keep structuring answers with STAR method for better flow.\",\n  \"generalFeedback\": \"Good job! You covered the basics, but there's room for more detail on X and Y.\",\n  \"detailedFeedback\": \"The answer was relevant (score 9) and clear (score 8). However, it lacked depth (score 7) as specific metrics or challenges were not fully explored. Suggestion: Next time, quantify your impact and provide more technical specifics.\"\n}\n```\n\nDo not include any conversational text, just the JSON output. Be constructive and specific in your remarks, offering actionable feedback where possible.";
}

export function UserPrompt(question: string, answer: string, mode: string): string {
    const encodedQuestion = mode === 'b64' ? encodeBase64(question) : sanitizeForLLM(question);
    const encodedAnswer = mode === 'b64' ? encodeBase64(answer) : sanitizeForLLM(answer);

    return `Please evaluate the following interview answer for the given question.\n\nInterview Question (base64 or plain):\n${encodedQuestion}\n\nCandidate's Answer (base64 or plain):\n${encodedAnswer}\n\nProvide the evaluation in the specified JSON format.`;
}
